{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import cPickle\n",
    "import urllib2\n",
    "import time\n",
    "import csv\n",
    "import twitter\n",
    "\n",
    "# Key and Secret hidden for security.\n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = ''\n",
    "OAUTH_TOKEN = ''\n",
    "OAUTH_TOKEN_SECRET = ''\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve county names\n",
    "with open('NYCountyNames.csv', 'r') as f:\n",
    "    county_names = list(csv.reader(f))[0]\n",
    "\n",
    "# Retrieve county locations and parse\n",
    "with open('nycountiesstrippedmiles.csv', 'r') as f:\n",
    "    lat_long_rad = list(csv.reader(f))\n",
    "county_locs = [lat + ',' + lon + ',' + rad + 'mi'\n",
    "               for (lat, lon, rad)\n",
    "               in zip(lat_long_rad[0], lat_long_rad[1], lat_long_rad[2])]\n",
    "\n",
    "# Geocodes (lat,lon,radius) indexed by the county name, but maybe\n",
    "# add empty string index/location to simply get all such tweets\n",
    "counties = dict(zip(county_names, county_locs))\n",
    "# counties[''] = ''\n",
    "\n",
    "# Hashtags to search\n",
    "q = ['feelthebern',\n",
    "     'sanders',\n",
    "     'berniesanders',\n",
    "     'bernie2016',\n",
    "     'clinton',\n",
    "     'hillaryclinton',\n",
    "     'imwithher',\n",
    "     'hillary2016',\n",
    "     'tedcruz',\n",
    "     'choosecruz',\n",
    "     'cruzcrew',\n",
    "     'unitewithcruz',\n",
    "     'cruz2016',\n",
    "     'trump2016',\n",
    "     'donaldtrump',\n",
    "     '#trump',\n",
    "     'donaldtrump2016',\n",
    "     'kasichcan',\n",
    "     'johnkasich',\n",
    "     'kasich2016',\n",
    "     'kasich4us',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search results will be stored herein. Within each county, we keep track\n",
    "# of the tweets we've found, indexed by hashtag and stored in the list.\n",
    "# We additionally keep a set of ids so we know when we find a tweet\n",
    "# that we've already seen.\n",
    "all_results = dict((county, dict((hashtag, ([], set())) for hashtag in q)) for county in counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actually retrieve results. Twitter sometimes rejects due to\n",
    "# rate limits; these are TwitterHTTPErrors. The connection also\n",
    "# sometimes gets dropped, which is the URLError.\n",
    "# Results are stored in pickles labeled with a number and the hashtag\n",
    "for i in xrange(10000):\n",
    "    for county in counties.keys():\n",
    "        for hashtag in q:\n",
    "            while True:\n",
    "                try:\n",
    "                    while True:\n",
    "                        try:\n",
    "                            results = twitter_api.search.tweets(q = hashtag,\n",
    "                                                                geocode = counties[county],\n",
    "                                                                count = 100) if county else twitter_api.search.tweets(q = hashtag,\n",
    "                                                                                                                      count = 100)\n",
    "                            break\n",
    "                        except twitter.api.TwitterHTTPError:\n",
    "                            print \"Oops, Twitter said 'slow down.' Trying again in 1 minute.\"\n",
    "                            time.sleep(60)\n",
    "                    break\n",
    "                except urllib2.URLError:\n",
    "                    print \"Oops, Twitter said 'no.' Trying again...\"\n",
    "            for num in xrange(len(results['statuses'])):\n",
    "                stat_id = results['statuses'][num]['id']\n",
    "                if stat_id not in all_results[county][hashtag][1]:\n",
    "                    all_results[county][hashtag][0].append(results['statuses'][num])\n",
    "                    all_results[county][hashtag][1].add(stat_id)\n",
    "            while True:\n",
    "                try:\n",
    "                    while True:\n",
    "                        try:\n",
    "                            while True:\n",
    "                                try:\n",
    "                                    next_results = results['search_metadata']['next_results']\n",
    "                                except KeyError, e: # No more results when next_results doesn't exist\n",
    "                                    print \"next_results doesn't exist\"\n",
    "                                    print county + hashtag + ': ' + str(len(all_results[county][hashtag][0])) + '/' + str(len(all_results[county][hashtag][1]))\n",
    "                                    if len(all_results[county][hashtag][0]) > 0:\n",
    "                                        with open('Tweets/' + county + '/' + hashtag + str(i) + '.p', 'wb') as f:\n",
    "                                            cPickle.dump(all_results[county][hashtag][0], f)\n",
    "                                        all_results[county][hashtag] = ([], all_results[county][hashtag][1])\n",
    "                                    break\n",
    "\n",
    "                                kwargs = dict([ kv.split('=') for kv in next_results[1:].split(\"&\") ])\n",
    "                                #print kwargs\n",
    "                                results = twitter_api.search.tweets(q = hashtag,\n",
    "                                                                    geocode = counties[county],\n",
    "                                                                    count = 100,\n",
    "                                                                    max_id = kwargs['max_id']) if county else twitter_api.search.tweets(q = hashtag,\n",
    "                                                                                                                                        count = '100',\n",
    "                                                                                                                                        max_id = kwargs['max_id'])\n",
    "\n",
    "                                for num in xrange(len(results['statuses'])):\n",
    "                                    stat_id = results['statuses'][num]['id']\n",
    "                                    if stat_id not in all_results[county][hashtag][1]:\n",
    "                                        #print stat_id\n",
    "                                        all_results[county][hashtag][0].append(results['statuses'][num])\n",
    "                                        all_results[county][hashtag][1].add(stat_id)\n",
    "                                if len(results['statuses']) < 100:\n",
    "                                    print 'end of pages'\n",
    "                                    print county + hashtag + ': ' + str(len(all_results[county][hashtag][0])) + '/' + str(len(all_results[county][hashtag][1]))\n",
    "                                    if len(all_results[county][hashtag][0]) > 0:\n",
    "                                        with open('Tweets/' + county + '/' + hashtag + str(i) + '.p', 'wb') as f:\n",
    "                                            cPickle.dump(all_results[county][hashtag][0], f)\n",
    "                                        all_results[county][hashtag] = ([], all_results[county][hashtag][1])\n",
    "                                    break\n",
    "                            break\n",
    "                        except urllib2.URLError:\n",
    "                            print \"Oops, Twitter said 'no.' Trying again...\"\n",
    "                    break\n",
    "                except twitter.api.TwitterHTTPError:\n",
    "                    print \"Oops, Twitter said 'slow down.' Trying again in 1 minute.\"\n",
    "                    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Code to make the directories we need\n",
    "for county in counties:\n",
    "    os.mkdir('Tweets/' + county)\n",
    "\n",
    "# Cleaning code to combine various pickled files\n",
    "# IOError might result if no results were returned for a hashtag at a certain i\n",
    "# EOFError might result if loop was stopped while writing to a pickle\n",
    "for county in counties:\n",
    "    for hashtag in q:\n",
    "        tag_results = []\n",
    "        for i in xrange(9):\n",
    "            try:\n",
    "                try:\n",
    "                    with open('Tweets/' + county + '/' + hashtag + str(i) + '.p', 'rb') as f:\n",
    "                        tag_results += cPickle.load(f)\n",
    "                except IOError:\n",
    "                    continue\n",
    "            except EOFError:\n",
    "                print county\n",
    "                print i\n",
    "                continue\n",
    "                \n",
    "        if tag_results:\n",
    "            with open('Tweets/' + county + '/' + hashtag + 'FULL' + '.p', 'wb') as f:\n",
    "                cPickle.dump(tag_results, f)\n",
    "                \n",
    "# Cleaning code to remove various pickled files\n",
    "for county in county_names:\n",
    "    for hashtag in q:\n",
    "        for i in xrange(9):\n",
    "            try:\n",
    "                os.remove('Tweets/' + county + '/' + hashtag + \"FULL\" + '.p')\n",
    "            except WindowsError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
